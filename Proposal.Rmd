---
title: "Final Project Proposal"
author: "Ashley L. Miller"
date: "2/2/2019"
output:
  html_document:
    highlight: zenburn
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}

# set knitr options
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      fig.width = 6.0,
                      fig.height = 3.5)

# load packages
library(rio)
library(here)
library(tidyverse)
library(magrittr)
library(ggforce)

# disable scientific notation
options(scipen = 999)

```

#### Description of the data source (must be publicly available)

I hope to use the final project as an opportunity to learn how to tidy/visualize my own data using R. Currently, to visualize data in my own research, I first typically obtain means and standard errors in SPSS, then I plot the data in Excel. This practice isn't exactly what I'd call ideal. 

The dataset I will be using is de-identified and already hosted on Github. The data comes from a recent publication of mine (Experiment 1; Miller, Gross, & Unsworth, 2019), in which pupil dilation was used as online indicator of the intensity of attention to determine whether variation in attention at encoding relates to individual differences in working memory capacity (WMC) and long-term memory (LTM) performance. Participants (*N* = 138) completed a battery of complex span working memory tasks, followed by a delayed free recall task while pupil dilation was simultaneously recorded.

An inspection of the data in it's current form reveals that a lot of tidying needs to be done (it's in wide form but needs to be in long form). The complete dataset consists of 183 variables, many of which will be irrelevant for the graphs I have selected to create (e.g., recall accuracy on the delayed free recall task broken down by serial position, encoding strategies). 

```{r load_data}

data <- import(here("data", "DeIntentifiedJML2019Data_Exp1.sav"),
               setclass = "tibble") %>% 
  characterize() %>%
  janitor::clean_names()

```

#### Preliminary ideas (even hand sketches) of different visualizations

  + Identification of the intended audience for each visualization
  + Note, you might consider displaying the same data/relations more than once, with each plot displayed for a different audience.
  + The intended message to be communicated for each plot.
  
![Figure 1 (Fig. 4 in Miller, Gross, & Unsworth, 2019). Pupil diameter as a function of time point (bin) at encoding of each word](/Users/amiller/Documents/Data Science/Winter 2019/EDLD610_T2_FinalProject/Preliminary graphs/Fig1.jpg)

![Figure 2 (Fig. 5. in Miller, Gross, & Unsworth, 2019). Pupil diameter as a function of serial position for high WMC (*n* = 33) and low WMC (*n* = 31) individuals.](/Users/amiller/Documents/Data Science/Winter 2019/EDLD610_T2_FinalProject/Preliminary graphs/Fig2.jpg)

![Figure 3 (Fig. 6. in Miller, Gross, & Unsworth, 2019). Pupil diameter as a function of serial position and bin (time across encoding period) for low WMC (*n* = 31) and high WMC (*n* = 33) individuals. Serial position was broken down into Primacy (items 1–3), Mid (items 4–7), and Recency (items 8–10) for graphical purposes only.](/Users/amiller/Documents/Data Science/Winter 2019/EDLD610_T2_FinalProject/Preliminary graphs/Fig3.jpg)
  
```{r preliminary_ideas}


```

